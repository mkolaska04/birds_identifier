{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c583f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from utils.data_loader import get_data_loaders\n",
    "from simple_classifiers import run_simple_classifiers\n",
    "from transfer_learning import run_transfer_learning\n",
    "from custom_cnn import run_custom_cnn\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Setup complete.\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73992c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, class_names = get_data_loaders()\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3fbb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_train_dataset = train_loader.dataset.dataset\n",
    "\n",
    "from utils.metrics_plotting import show_augmentation_examples\n",
    "\n",
    "show_augmentation_examples(dataset=full_train_dataset, class_names=class_names, num_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b05a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simple_classifiers(train_loader, test_loader, class_names, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780d1c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_features(dataloader, model, device):\n",
    "    features, labels = [], []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(dataloader, desc=\"Extracting features\"):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs).cpu().numpy()\n",
    "            features.append(outputs)\n",
    "            labels.append(targets.numpy())\n",
    "    return np.vstack(features), np.hstack(labels)\n",
    "\n",
    "try:\n",
    "    X_test.shape\n",
    "    y_test.shape\n",
    "    print(\"Używam wcześniej wyekstrahowanych cech ze zbioru testowego.\")\n",
    "except NameError:\n",
    "    print(\"Cechy nie zostały znalezione. Uruchamiam ekstrakcję na nowo...\")\n",
    "    backbone = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT).features\n",
    "    feature_extractor = nn.Sequential(backbone, nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten()).to(DEVICE)\n",
    "    \n",
    "\n",
    "    print(\"Ekstrahuję cechy tylko dla zbioru testowego...\")\n",
    "    X_test, y_test = extract_features(test_loader, feature_extractor, DEVICE)\n",
    " \n",
    "\n",
    "num_points_to_plot = 2000\n",
    "if len(X_test) > num_points_to_plot:\n",
    "    print(f\"\\nUżywam losowej próbki {num_points_to_plot} punktów do wizualizacji t-SNE...\")\n",
    "    random_indices = np.random.choice(len(X_test), size=num_points_to_plot, replace=False)\n",
    "    X_subset = X_test[random_indices]\n",
    "    y_subset = y_test[random_indices]\n",
    "else:\n",
    "    X_subset = X_test\n",
    "    y_subset = y_test\n",
    "\n",
    "print(\"Uruchamiam algorytm t-SNE... To może potrwać kilka minut.\")\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42, max_iter=300, n_jobs=-1)\n",
    "tsne_results = tsne.fit_transform(X_subset)\n",
    "print(\"t-SNE zakończone.\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.scatterplot(\n",
    "    x=tsne_results[:, 0], \n",
    "    y=tsne_results[:, 1],\n",
    "    hue=y_subset,\n",
    "    palette=sns.color_palette(\"hsv\", n_colors=len(np.unique(y_subset))),\n",
    "    legend=False,\n",
    "    alpha=0.7,\n",
    "    s=50\n",
    ")\n",
    "\n",
    "plt.title('Wizualizacja Cech Obrazów za pomocą t-SNE', fontsize=16)\n",
    "plt.xlabel('Komponent t-SNE 1')\n",
    "plt.ylabel('Komponent t-SNE 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c23543",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_transfer_learning(\"MobileNetV2\", num_classes, train_loader, val_loader, test_loader, class_names, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1bd4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_transfer_learning(\"ResNet50\", num_classes, train_loader, val_loader, test_loader, class_names, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f0ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_transfer_learning(\"EfficientNetB0\", num_classes, train_loader, val_loader, test_loader, class_names, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e18569",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from custom_cnn import run_custom_cnn\n",
    "\n",
    "\n",
    "BEST_LR = 0.001 \n",
    "\n",
    "run_custom_cnn(num_classes, train_loader, val_loader, test_loader, class_names, DEVICE, lr=BEST_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2279ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_cnn import FinalCNN, find_lr\n",
    "import torch.nn as nn\n",
    "\n",
    "test_model = FinalCNN(num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "find_lr(test_model, train_loader, criterion, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3517a407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision_transformer import run_vision_transformer\n",
    "\n",
    "run_vision_transformer(num_classes, train_loader, val_loader, test_loader, class_names, DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
